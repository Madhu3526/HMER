# ðŸ“ Handwritten Mathematical Expression Recognition

## Project Overview
This project focuses on converting handwritten mathematical expressions into digital **LaTeX** using three progressively advanced machine learning approaches:

- **Multi-Layer Perceptron (MLP)** â€“ Baseline character classifier  
- **Basic Convolutional Neural Network (CNN)** â€“ Stronger character-level OCR  
- **Encoderâ€“Decoder with Attention (ResNet50V2 + LSTM)** â€“ End-to-end Image-to-LaTeX model  

---

## ðŸ“‚ Dataset: MathWriting (Derived from CROHME)

- **Total Samples:** ~4,45,538 handwritten mathematical expressions  
- **Source Format:** InkML (converted to PNG)  
- **Input:** PNG images of handwritten formulas  
- **Output:** Ground-truth LaTeX formula  
- **Character Vocabulary (MLP/CNN):** 82 unique classes  
- **LaTeX Vocabulary (Seq2Seq):** 64,000+ unique tokens  

---

## ðŸ”§ Approach 1 â€” Multi-Layer Perceptron (MLP)

A segmentation-based pipeline designed for isolated character recognition.

### ðŸ”¹ Workflow
- Binarization using *adaptive thresholding*  
- Character extraction using **cv2.findContours**  
- Cropping & resizing characters to **45 Ã— 45**  
- Flattening to a **2025-dimensional vector**  
- Classification using MLP  

### ðŸ”¹ Model Architecture
2025 â†’ 256 â†’ 128 â†’ 82
(ReLU activations + Dropout layers)


### ðŸ”¹ Performance
- âœ” Achieved **~98% accuracy** on isolated characters  
- âŒ Cannot model 2D math structure (fractions, roots, superscripts)  

---

## ðŸ”§ Approach 2 â€” Basic CNN

Improved character-level OCR using convolutional feature extraction.

### ðŸ”¹ Architecture
- 3 Ã— `Conv2D(32, 3Ã—3)` + MaxPooling  
- Fully connected: `Dense(128) â†’ Dense(82)`  

### ðŸ”¹ Performance
- âœ” Achieved **~95% accuracy**  
- âŒ Still segmentation-based â†’ fails for full mathematical expressions  

---

## ðŸ”§ Approach 3 â€” Encoderâ€“Decoder with Attention (Final Model)

A complete **Image-to-LaTeX** deep learning system with end-to-end learning.

### ðŸ”¹ Encoder
- **ResNet50V2** pretrained on ImageNet  
- Extracts high-level 2D spatial features  

### ðŸ”¹ Attention
- **Bahdanau Attention**  
- Focuses on relevant image regions during token generation  

### ðŸ”¹ Decoder
- **LSTM** generating LaTeX tokens sequentially  
- Vocabulary size: **64k+ tokens**  

### ðŸ”¹ Training
- **5 epochs** â€“ Encoder feature extraction  
- **3 epochs** â€“ Fine-tuning  
- **Training Loss:** 0.538  
- **Validation Loss:** 0.870  

### ðŸ”¹ Evaluation
- **Exact Match Rate (EMR):** 9.50%  
- **Character Error Rate (CER):** 80.17%  
> *Despite low EMR due to dataset complexity, the model successfully learns spatial structure and generates structurally meaningful LaTeX expressions.*

---
